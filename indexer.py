# -*- coding: utf-8 -*-
"""
RTX 3050 Optimized ChromaDB Indexing Script (BGE-M3 1024-dim Version)
ä¿®æ­£ç¶­åº¦ä¸åŒ¹é… (Dimension Mismatch) èˆ‡ GPU æ•ˆèƒ½å„ªåŒ–
"""
import os
import json
import sys
import torch
import chromadb
from sentence_transformers import SentenceTransformer

# --- é…ç½®å€ ---
DB_PATH = "./chroma_db"
COLLECTION_NAME = "ntu_assistant"
CHUNKS_PATH = "data/processed_chunks.json" 
EMBEDDING_MODEL = "BAAI/bge-m3"

class BGEM3EmbeddingFunctionGPU:
    def __init__(self):
        # 1. é æª¢æ¸¬è©¦ï¼šç¢ºä¿ä½¿ç”¨çš„æ˜¯ GPU 0 (RTX 3050)
        if not torch.cuda.is_available():
            print("\nâŒ éŒ¯èª¤ï¼šæœªåµæ¸¬åˆ° CUDA ç’°å¢ƒï¼è«‹æª¢æŸ¥ PyTorch å®‰è£ã€‚")
            sys.exit(1)

        self.device = "cuda:0"
        self.gpu_name = torch.cuda.get_device_name(0)
        
        print(f"\n[é æª¢æˆåŠŸ] æ­£åœ¨ä½¿ç”¨ GPU: {self.gpu_name}")
        print(f"æ­£åœ¨è¼‰å…¥æ¨¡å‹: {EMBEDDING_MODEL}...")
        
        # 2. è¼‰å…¥æ¨¡å‹
        self.model = SentenceTransformer(EMBEDDING_MODEL, device=self.device)
        
        # 3. 4GB é¡¯å­˜é—œéµå„ªåŒ–ï¼šFP16 åŠç²¾åº¦
        # é€™èƒ½å°‡é¡¯å­˜ä½”ç”¨å¾ç´„ 3.5GB å£“ä½è‡³ 2.2GB å·¦å³
        self.model.half()
        print("âœ¨ å·²å•Ÿç”¨ FP16 åŠç²¾åº¦å„ªåŒ– (ç¢ºä¿ 4GB é¡¯å­˜ç©©å®šé‹ä½œ)")

    # å¿…é ˆå¯¦ä½œæ­¤æ–¹æ³•ä»¥ç¬¦åˆ ChromaDB ä»‹é¢
    def name(self) -> str:
        return "BAAI_BGE_M3_GPU"

    def __call__(self, input: list) -> list:
        # ChromaDB å‚³å…¥æ–‡æœ¬åˆ—è¡¨ï¼Œè¿”å›å‘é‡åˆ—è¡¨
        embeddings = self.model.encode(
            input, 
            batch_size=12,           # é‡å° 4GB é¡¯å­˜çš„å®‰å…¨æ‰¹æ¬¡
            normalize_embeddings=True, # BGE-M3 å»ºè­°é–‹å•Ÿä»¥åˆ© Cosine é‹ç®—
            show_progress_bar=False
        )
        return embeddings.tolist()

def main():
    print("--- è…³æœ¬å•Ÿå‹• ---")
    
    # æª¢æŸ¥åŸå§‹è³‡æ–™è·¯å¾‘
    if not os.path.exists(CHUNKS_PATH):
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°è³‡æ–™æª”æ¡ˆ {CHUNKS_PATH}")
        print(f"ç›®å‰åŸ·è¡Œä½ç½®: {os.getcwd()}")
        return

    # åˆå§‹åŒ–åµŒå…¥å‡½æ•¸
    embedding_fn = BGEM3EmbeddingFunctionGPU()

    # åˆå§‹åŒ– ChromaDB
    print(f"æ­£åœ¨åˆå§‹åŒ– ChromaDB æ–¼ {DB_PATH}...")
    client = chromadb.PersistentClient(path=DB_PATH)

    # --- é—œéµä¿®æ­£ï¼šè§£æ±ºç¶­åº¦ä¸åŒ¹é… (384 vs 1024) ---
    try:
        # æª¢æŸ¥æ˜¯å¦å­˜åœ¨åŒåä½†ç¶­åº¦éŒ¯èª¤çš„ Collection
        existing_collections = [c.name for c in client.list_collections()]
        if COLLECTION_NAME in existing_collections:
            print(f"âš ï¸ åµæ¸¬åˆ°èˆŠçš„ Collectionã€‚æ­£åœ¨é‡ç½®ä»¥åŒ¹é… BGE-M3 (1024 ç¶­åº¦)...")
            client.delete_collection(name=COLLECTION_NAME)
    except Exception as e:
        print(f"é‡ç½® Collection æ™‚ç™¼ç”Ÿå°éŒ¯èª¤ (å¯å¿½ç•¥): {e}")

    # å»ºç«‹å…¨æ–°çš„ Collection
    collection = client.get_or_create_collection(
        name=COLLECTION_NAME,
        embedding_function=embedding_fn,
        metadata={"hnsw:space": "cosine"}
    )

    # è®€å– JSON è³‡æ–™
    print(f"æ­£åœ¨è®€å– {CHUNKS_PATH}...")
    with open(CHUNKS_PATH, "r", encoding="utf-8") as f:
        chunks = json.load(f)

    documents = [c["text"] for c in chunks]
    metadatas = [c["metadata"] for c in chunks]
    ids = [f"chunk_{i}" for i in range(len(chunks))]

    # é–‹å§‹åˆ†æ‰¹å¯«å…¥è³‡æ–™åº«
    batch_size = 50 
    total = len(documents)
    print(f"é–‹å§‹å»ºç«‹ç´¢å¼• (ç¸½è¨ˆ {total} ç­†è³‡æ–™)...")

    for i in range(0, total, batch_size):
        end = min(i + batch_size, total)
        try:
            collection.add(
                documents=documents[i:end],
                metadatas=metadatas[i:end],
                ids=ids[i:end]
            )
            print(f"ğŸš€ é€²åº¦: {end}/{total} ({(end/total)*100:.1f}%)")
        except Exception as e:
            print(f"ğŸ’¥ å¯«å…¥æ‰¹æ¬¡ç™¼ç”ŸéŒ¯èª¤: {e}")
            break

    print(f"\nâœ… å…¨éƒ¨ç´¢å¼•å»ºç«‹å®Œæˆï¼")
    print(f"è³‡æ–™åº«ç¸½ç­†æ•¸: {collection.count()}")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\nä½¿ç”¨è€…åœæ­¢ç¨‹å¼ã€‚")
    except Exception as e:
        print(f"\nğŸ’¥ åŸ·è¡Œéç¨‹ç™¼ç”Ÿæœªé æœŸçš„åš´é‡éŒ¯èª¤: {e}")